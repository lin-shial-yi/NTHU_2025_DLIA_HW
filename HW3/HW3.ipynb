{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f' Using device: {device}')"
      ],
      "metadata": {
        "id": "hss100mtW_6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4732e09-c063-4ce8-a6e2-e5160e9b71af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question1\n"
      ],
      "metadata": {
        "id": "sF4sT3H2OVTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQA2FLjyBP53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3791ab48-2494-4f1d-bf79-c20ca96c23a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/bottle/ground_truth/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !unzip /content/drive/MyDrive/bottle-20250407T063408Z-001.zip\n",
        "!rm -r /content/bottle/ground_truth/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images used\n",
        "\n",
        "def count_images_in_folder(folder_path):\n",
        "    return len([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "base_dir = 'bottle'\n",
        "train_dir = os.path.join(base_dir, 'train', 'good')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "test_classes = ['broken_large', 'broken_small', 'contamination', 'good']\n",
        "\n",
        "total_images = 0\n",
        "train_count = count_images_in_folder(train_dir)\n",
        "total_images += train_count\n",
        "\n",
        "test_counts = {}\n",
        "for cls in test_classes:\n",
        "    cls_path = os.path.join(test_dir, cls)\n",
        "    test_counts[cls] = count_images_in_folder(cls_path)\n",
        "    total_images += test_counts[cls]\n",
        "\n",
        "print(f\"訓練集圖片數量: {train_count}\")\n",
        "print(\"測試集各類別圖片數量:\")\n",
        "for k, v in test_counts.items():\n",
        "    print(f\"  - {k}: {v} 張\")\n",
        "print(f\"總圖片數量: {total_images}\")"
      ],
      "metadata": {
        "id": "n9Dv_CUlCeiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e33d3d7-9d4b-46f1-a87f-65b591f4c49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練集圖片數量: 209\n",
            "測試集各類別圖片數量:\n",
            "  - broken_large: 20 張\n",
            "  - broken_small: 22 張\n",
            "  - contamination: 21 張\n",
            "  - good: 20 張\n",
            "總圖片數量: 292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image dimensions\n",
        "sample_img_path = os.path.join(train_dir, os.listdir(train_dir)[0])\n",
        "img = Image.open(sample_img_path)\n",
        "print(f\"影像尺寸: {img.size} (width x height)\")"
      ],
      "metadata": {
        "id": "_M6jiBBYKAbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9756e528-3f94-49fa-af0e-f64151e3c236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "影像尺寸: (900, 900) (width x height)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question2"
      ],
      "metadata": {
        "id": "zoA1_pluOcgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1: Baseline Deep SVDD（Simple CNN）\n"
      ],
      "metadata": {
        "id": "if8RtwyXh2gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# 1. 超參數\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 128\n",
        "EPOCHS = 20\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 2. 資料增強 + 前處理\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# 3. 載入訓練資料（只有 good）\n",
        "train_dir = 'bottle/train/good'\n",
        "train_dataset = datasets.ImageFolder(root=os.path.dirname(train_dir), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# 4. CNN 特徵萃取模型\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, out_dim=128):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 5. 初始化中心點 c\n",
        "def get_init_center(model, loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            out = model(x)\n",
        "            outputs.append(out)\n",
        "    all_feats = torch.cat(outputs)\n",
        "    return torch.mean(all_feats, dim=0)\n",
        "\n",
        "center_c = get_init_center(model, train_loader).detach()\n",
        "\n",
        "# 6. 訓練 Deep SVDD：最小化與中心 c 的距離\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        loss = torch.mean(torch.sum((feat - center_c) ** 2, dim=1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {np.mean(losses)}\")\n"
      ],
      "metadata": {
        "id": "KAMZ2xpMh9N_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8645d4b-5770-44b1-aa15-49652e347088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Loss: 0.00035729595141934363\n",
            "Epoch 2/20 - Loss: 0.00013535481931674958\n",
            "Epoch 3/20 - Loss: 7.424688711970313e-05\n",
            "Epoch 4/20 - Loss: 4.010630722664895e-05\n",
            "Epoch 5/20 - Loss: 2.2183275827306454e-05\n",
            "Epoch 6/20 - Loss: 1.5340047996557716e-05\n",
            "Epoch 7/20 - Loss: 1.106273781000969e-05\n",
            "Epoch 8/20 - Loss: 9.03044747246895e-06\n",
            "Epoch 9/20 - Loss: 8.225047232761945e-06\n",
            "Epoch 10/20 - Loss: 7.1645557519722e-06\n",
            "Epoch 11/20 - Loss: 6.6832679164820415e-06\n",
            "Epoch 12/20 - Loss: 6.4873692541108796e-06\n",
            "Epoch 13/20 - Loss: 6.498223813520911e-06\n",
            "Epoch 14/20 - Loss: 7.000891595712996e-06\n",
            "Epoch 15/20 - Loss: 7.488056066254753e-06\n",
            "Epoch 16/20 - Loss: 6.67018931770664e-06\n",
            "Epoch 17/20 - Loss: 5.9951876210107e-06\n",
            "Epoch 18/20 - Loss: 6.028211893343334e-06\n",
            "Epoch 19/20 - Loss: 6.1449779553056165e-06\n",
            "Epoch 20/20 - Loss: 6.2518991269046505e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "\n",
        "# 1. 建立測試集資料\n",
        "test_dir = 'bottle/test'\n",
        "test_classes = ['good', 'broken_large', 'broken_small', 'contamination']\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for cls in test_classes:\n",
        "    folder = os.path.join(test_dir, cls)\n",
        "    for img_name in os.listdir(folder):\n",
        "        if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            test_images.append(img_path)\n",
        "            test_labels.append(0 if cls == 'good' else 1)  # good = 0, abnormal = 1\n",
        "\n",
        "# 2. 定義圖像前處理\n",
        "def preprocess_image(path):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "# 3. 計算每張圖片的距離分數\n",
        "model.eval()\n",
        "scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for path in tqdm(test_images):\n",
        "        img = preprocess_image(path).unsqueeze(0).to(DEVICE)\n",
        "        feat = model(img)\n",
        "        score = torch.sum((feat - center_c) ** 2, dim=1)  # 歐式距離平方\n",
        "        scores.append(score.item())\n",
        "\n",
        "# 4. 設定閾值（95 percentile of train set distance）\n",
        "train_distances = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        dist = torch.sum((feat - center_c) ** 2, dim=1)\n",
        "        train_distances.extend(dist.cpu().numpy())\n",
        "\n",
        "threshold = np.percentile(train_distances, 95)  # 調整這個也可以做 sensitivity 分析\n",
        "print(f\"使用的距離閾值：{threshold}\")\n",
        "\n",
        "# 5. 預測結果 & 評估\n",
        "preds = [1 if score > threshold else 0 for score in scores]\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(test_labels, preds, target_names=['good', 'anomaly']))\n",
        "\n",
        "auc = roc_auc_score(test_labels, scores)\n",
        "print(f\"🔍 ROC AUC Score: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "uyLr0ma6iRcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825ba574-8fa2-4fdf-c01c-66fc0f27d6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:03<00:00, 25.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用的距離閾值：1.6692018107278273e-05\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.25      0.75      0.37        20\n",
            "     anomaly       0.77      0.27      0.40        63\n",
            "\n",
            "    accuracy                           0.39        83\n",
            "   macro avg       0.51      0.51      0.39        83\n",
            "weighted avg       0.65      0.39      0.39        83\n",
            "\n",
            "🔍 ROC AUC Score: 0.5714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 2: ResNet18取代CNN"
      ],
      "metadata": {
        "id": "PFoOVWBFpYvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ==== 參數 ====\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224\n",
        "EPOCHS = 20\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ==== 資料前處理 ====\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet 的均值與標準差\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ==== 載入 train/good 圖片 ====\n",
        "train_dir = 'bottle/train/good'\n",
        "train_dataset = datasets.ImageFolder(root=os.path.dirname(train_dir), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# ==== 修改 ResNet18 模型 ====\n",
        "class ResNet18FeatureExtractor(nn.Module):\n",
        "    def __init__(self, output_dim=128):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]  # 去掉最後分類層 fc\n",
        "        self.backbone = nn.Sequential(*modules)\n",
        "        self.fc = nn.Linear(512, output_dim)  # 加上轉換層\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten (B, 512)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = ResNet18FeatureExtractor().to(DEVICE)\n",
        "\n",
        "# ==== SVDD 損失與優化器 ====\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ==== 初始化中心點 c ====\n",
        "def get_init_center(model, loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            feat = model(x)\n",
        "            outputs.append(feat)\n",
        "    all_feats = torch.cat(outputs)\n",
        "    return torch.mean(all_feats, dim=0)\n",
        "\n",
        "center_c = get_init_center(model, train_loader).detach()\n",
        "\n",
        "# ==== 訓練 Deep SVDD ====\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        loss = torch.mean(torch.sum((feat - center_c) ** 2, dim=1))  # L2 距離平方\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {np.mean(losses):.4f}\")\n",
        "\n",
        "# ==== 計算訓練資料距離以設定閾值 ====\n",
        "train_distances = []\n",
        "with torch.no_grad():\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        dist = torch.sum((feat - center_c) ** 2, dim=1)\n",
        "        train_distances.extend(dist.cpu().numpy())\n",
        "\n",
        "threshold = np.percentile(train_distances, 95)\n",
        "print(f\"\\n✅ 使用的距離閾值：{threshold}\")\n",
        "\n",
        "# ==== 測試 ====\n",
        "test_dir = 'bottle/test'\n",
        "test_classes = ['good', 'broken_large', 'broken_small', 'contamination']\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for cls in test_classes:\n",
        "    folder = os.path.join(test_dir, cls)\n",
        "    for img_name in os.listdir(folder):\n",
        "        if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            test_images.append(img_path)\n",
        "            test_labels.append(0 if cls == 'good' else 1)\n",
        "\n",
        "def preprocess_image(path):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "model.eval()\n",
        "scores = []\n",
        "with torch.no_grad():\n",
        "    for path in tqdm(test_images):\n",
        "        img = preprocess_image(path).unsqueeze(0).to(DEVICE)\n",
        "        feat = model(img)\n",
        "        score = torch.sum((feat - center_c) ** 2, dim=1)\n",
        "        scores.append(score.item())\n",
        "\n",
        "# ==== 評估 ====\n",
        "preds = [1 if score > threshold else 0 for score in scores]\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(test_labels, preds, target_names=['good', 'anomaly']))\n",
        "\n",
        "auc = roc_auc_score(test_labels, scores)\n",
        "print(f\"🔍 ROC AUC Score: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdYcD3R5sJZm",
        "outputId": "97e7ac1d-88cb-4ed2-827b-28f584cdad25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Loss: 29.6427\n",
            "Epoch 2/20 - Loss: 4.3604\n",
            "Epoch 3/20 - Loss: 0.8684\n",
            "Epoch 4/20 - Loss: 0.4549\n",
            "Epoch 5/20 - Loss: 0.1662\n",
            "Epoch 6/20 - Loss: 0.0784\n",
            "Epoch 7/20 - Loss: 0.0510\n",
            "Epoch 8/20 - Loss: 0.0326\n",
            "Epoch 9/20 - Loss: 0.0248\n",
            "Epoch 10/20 - Loss: 0.0194\n",
            "Epoch 11/20 - Loss: 0.0167\n",
            "Epoch 12/20 - Loss: 0.0148\n",
            "Epoch 13/20 - Loss: 0.0134\n",
            "Epoch 14/20 - Loss: 0.0124\n",
            "Epoch 15/20 - Loss: 0.0116\n",
            "Epoch 16/20 - Loss: 0.0110\n",
            "Epoch 17/20 - Loss: 0.0104\n",
            "Epoch 18/20 - Loss: 0.0098\n",
            "Epoch 19/20 - Loss: 0.0094\n",
            "Epoch 20/20 - Loss: 0.0089\n",
            "\n",
            "✅ 使用的距離閾值：0.012546464800834656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:03<00:00, 24.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       1.00      0.25      0.40        20\n",
            "     anomaly       0.81      1.00      0.89        63\n",
            "\n",
            "    accuracy                           0.82        83\n",
            "   macro avg       0.90      0.62      0.65        83\n",
            "weighted avg       0.85      0.82      0.77        83\n",
            "\n",
            "🔍 ROC AUC Score: 0.9960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 3: 加上data augmentation"
      ],
      "metadata": {
        "id": "DlcMmR5Iqxaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 相比於方法二，只需要調整transform。\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "QvAh0gx6qeQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 參數 ====\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224\n",
        "EPOCHS = 20\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ==== 資料前處理 ====\n",
        "transform = train_transform\n",
        "\n",
        "# ==== 載入 train/good 圖片 ====\n",
        "train_dir = 'bottle/train/good'\n",
        "train_dataset = datasets.ImageFolder(root=os.path.dirname(train_dir), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# ==== 修改 ResNet18 模型 ====\n",
        "class ResNet18FeatureExtractor(nn.Module):\n",
        "    def __init__(self, output_dim=128):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]  # 去掉最後分類層 fc\n",
        "        self.backbone = nn.Sequential(*modules)\n",
        "        self.fc = nn.Linear(512, output_dim)  # 加上轉換層\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten (B, 512)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = ResNet18FeatureExtractor().to(DEVICE)\n",
        "\n",
        "# ==== SVDD 損失與優化器 ====\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ==== 初始化中心點 c ====\n",
        "def get_init_center(model, loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            feat = model(x)\n",
        "            outputs.append(feat)\n",
        "    all_feats = torch.cat(outputs)\n",
        "    return torch.mean(all_feats, dim=0)\n",
        "\n",
        "center_c = get_init_center(model, train_loader).detach()\n",
        "\n",
        "# ==== 訓練 Deep SVDD ====\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        loss = torch.mean(torch.sum((feat - center_c) ** 2, dim=1))  # L2 距離平方\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {np.mean(losses):.4f}\")\n",
        "\n",
        "# ==== 計算訓練資料距離以設定閾值 ====\n",
        "train_distances = []\n",
        "with torch.no_grad():\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        dist = torch.sum((feat - center_c) ** 2, dim=1)\n",
        "        train_distances.extend(dist.cpu().numpy())\n",
        "\n",
        "threshold = np.percentile(train_distances, 95)\n",
        "print(f\"\\n✅ 使用的距離閾值：{threshold}\")\n",
        "\n",
        "# ==== 測試 ====\n",
        "test_dir = 'bottle/test'\n",
        "test_classes = ['good', 'broken_large', 'broken_small', 'contamination']\n",
        "test_images = []\n",
        "test_labels = []\n",
        "transform = test_transform\n",
        "for cls in test_classes:\n",
        "    folder = os.path.join(test_dir, cls)\n",
        "    for img_name in os.listdir(folder):\n",
        "        if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            test_images.append(img_path)\n",
        "            test_labels.append(0 if cls == 'good' else 1)\n",
        "\n",
        "def preprocess_image(path):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "model.eval()\n",
        "scores = []\n",
        "with torch.no_grad():\n",
        "    for path in tqdm(test_images):\n",
        "        img = preprocess_image(path).unsqueeze(0).to(DEVICE)\n",
        "        feat = model(img)\n",
        "        score = torch.sum((feat - center_c) ** 2, dim=1)\n",
        "        scores.append(score.item())\n",
        "\n",
        "# ==== 評估 ====\n",
        "preds = [1 if score > threshold else 0 for score in scores]\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(test_labels, preds, target_names=['good', 'anomaly']))\n",
        "\n",
        "auc = roc_auc_score(test_labels, scores)\n",
        "print(f\"🔍 ROC AUC Score: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ-Pq-a5tUOO",
        "outputId": "d54bb75c-91d1-4069-e931-69a3986b292b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Loss: 30.4516\n",
            "Epoch 2/20 - Loss: 7.4997\n",
            "Epoch 3/20 - Loss: 2.2265\n",
            "Epoch 4/20 - Loss: 0.9296\n",
            "Epoch 5/20 - Loss: 0.5097\n",
            "Epoch 6/20 - Loss: 0.2991\n",
            "Epoch 7/20 - Loss: 0.1697\n",
            "Epoch 8/20 - Loss: 0.1187\n",
            "Epoch 9/20 - Loss: 0.0904\n",
            "Epoch 10/20 - Loss: 0.0767\n",
            "Epoch 11/20 - Loss: 0.0620\n",
            "Epoch 12/20 - Loss: 0.0580\n",
            "Epoch 13/20 - Loss: 0.0520\n",
            "Epoch 14/20 - Loss: 0.0475\n",
            "Epoch 15/20 - Loss: 0.0447\n",
            "Epoch 16/20 - Loss: 0.0422\n",
            "Epoch 17/20 - Loss: 0.0393\n",
            "Epoch 18/20 - Loss: 0.0359\n",
            "Epoch 19/20 - Loss: 0.0349\n",
            "Epoch 20/20 - Loss: 0.0335\n",
            "\n",
            "✅ 使用的距離閾值：0.048705387860536575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:03<00:00, 22.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.83      1.00      0.91        20\n",
            "     anomaly       1.00      0.94      0.97        63\n",
            "\n",
            "    accuracy                           0.95        83\n",
            "   macro avg       0.92      0.97      0.94        83\n",
            "weighted avg       0.96      0.95      0.95        83\n",
            "\n",
            "🔍 ROC AUC Score: 0.9889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 4: 把 歐式距離平方 改成用 Mahalanobis 距離"
      ],
      "metadata": {
        "id": "F3r0vXI5uwpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from PIL import Image\n",
        "\n",
        "# 🔹 1. 建立測試資料列表與標籤\n",
        "test_dir = 'bottle/test'\n",
        "test_classes = ['good', 'broken_large', 'broken_small', 'contamination']\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for cls in test_classes:\n",
        "    folder = os.path.join(test_dir, cls)\n",
        "    for img_name in os.listdir(folder):\n",
        "        if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            test_images.append(img_path)\n",
        "            test_labels.append(0 if cls == 'good' else 1)\n",
        "\n",
        "# 🔹 2. 使用與訓練相同的 transform\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def preprocess_image(path):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = test_transform(image)\n",
        "    return image\n",
        "\n",
        "# 🔹 3. 取得訓練特徵向量 → 計算 mean & covariance\n",
        "model.eval()\n",
        "train_features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, _ in train_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        feat = model(x)\n",
        "        train_features.append(feat.cpu())\n",
        "\n",
        "train_features = torch.cat(train_features, dim=0).numpy()\n",
        "mean_vec = np.mean(train_features, axis=0)\n",
        "cov_mat = np.cov(train_features, rowvar=False)\n",
        "\n",
        "# 正則化避免奇異矩陣\n",
        "eps = 1e-6\n",
        "cov_mat += eps * np.eye(cov_mat.shape[0])\n",
        "inv_cov = inv(cov_mat)\n",
        "\n",
        "# 🔹 4. 定義 Mahalanobis 距離計算\n",
        "def mahalanobis_distance(x, mean_vec, inv_cov):\n",
        "    diff = x - mean_vec\n",
        "    return np.sqrt(np.dot(np.dot(diff, inv_cov), diff.T))\n",
        "\n",
        "# 🔹 5. 測試所有 test 圖像，計算 Mahalanobis 距離\n",
        "mahalanobis_scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for path in tqdm(test_images):\n",
        "        img = preprocess_image(path).unsqueeze(0).to(DEVICE)\n",
        "        feat = model(img).cpu().numpy().squeeze()\n",
        "        score = mahalanobis_distance(feat, mean_vec, inv_cov)\n",
        "        mahalanobis_scores.append(score)\n",
        "\n",
        "# 🔹 6. 設定閾值（95% 訓練資料 Mahalanobis 距離）\n",
        "train_distances = [mahalanobis_distance(f, mean_vec, inv_cov) for f in train_features]\n",
        "threshold = np.percentile(train_distances, 95)\n",
        "print(f\"\\n✅ Mahalanobis 閾值：{threshold:.4f}\")\n",
        "\n",
        "# 🔹 7. 預測 & 評估\n",
        "preds = [1 if s > threshold else 0 for s in mahalanobis_scores]\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(test_labels, preds, target_names=['good', 'anomaly']))\n",
        "\n",
        "auc = roc_auc_score(test_labels, mahalanobis_scores)\n",
        "print(f\"🔍 ROC AUC Score: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZtTsbGAtkuj",
        "outputId": "35d96c3b-fba7-4dfe-d754-745704c92abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:03<00:00, 24.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Mahalanobis 閾值：12.1587\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.00      0.00      0.00        20\n",
            "     anomaly       0.76      1.00      0.86        63\n",
            "\n",
            "    accuracy                           0.76        83\n",
            "   macro avg       0.38      0.50      0.43        83\n",
            "weighted avg       0.58      0.76      0.66        83\n",
            "\n",
            "🔍 ROC AUC Score: 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}